# Agent backend/model configuration for VERN
# Specify which backend/model/API each agent should use.
# Format for Ollama: "ollama-<model>"
# Example: "ollama-qwen3:0.6b", "ollama-phi", "fake_llm", "qwen3-0.6b" (transformers)

default: ollama-qwen3:0.6b

backends:
  ollama-qwen3:0.6b:
    provider: ollama
    model: qwen3:0.6b
  ollama-phi:
    provider: ollama
    model: phi
  openai-gpt-4:
    provider: openai
    model: gpt-4

# Per-agent backend selection (optional, for future advanced workflows)
agents:
  dev_team: ollama-qwen3:0.6b
  knowledge_broker: ollama-qwen3:0.6b
  research: ollama-qwen3:0.6b
  admin: ollama-qwen3:0.6b

# --- NEW: ASR (Speech-to-Text) backends ---
default_asr: whisper-base

asr_backends:
  whisper-base:
    provider: whisper
    model: base
  whisper-tiny:
    provider: whisper
    model: tiny
  google-speech:
    provider: google
    model: speech-to-text
  espeak-asr:
    provider: espeak
    model: default

asr_agents:
  dev_team: whisper-base
  admin: google-speech

# --- NEW: TTS (Text-to-Speech) backends ---
default_tts: coqui-tts

tts_backends:
  coqui-tts:
    provider: coqui
    model: tts_models/en/ljspeech/tacotron2-DDC
  google-tts:
    provider: google
    model: text-to-speech
  espeak-tts:
    provider: espeak
    model: default

tts_agents:
  dev_team: coqui-tts
  admin: google-tts

# --- Vision backends (future extension) ---
default_vision: tesseract

vision_backends:
  tesseract:
    provider: tesseract
    model: default
  google-vision:
    provider: google
    model: vision-api

vision_agents:
  dev_team: tesseract
  admin: google-vision
